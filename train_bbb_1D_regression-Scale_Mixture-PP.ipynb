{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "# from torchvision import datasets, transforms\n",
    "# from torchvision.utils import make_grid\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# writer = SummaryWriter()\n",
    "sns.set()\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_palette(\"muted\")\n",
    "sns.set_color_codes(\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? False\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "print('GPU available? {}'.format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_function(N):\n",
    "    \n",
    "    noise_std = 0.02\n",
    "    eps_train = noise_std*np.random.randn(N,)\n",
    "    eps_test =  noise_std*np.random.randn(int(N*0.5),)\n",
    "    \n",
    "    \n",
    "    x_train = np.linspace(0, 0.5, N, endpoint=True, dtype =np.float32)\n",
    "    x_test =  np.linspace(-1, 1, int(N*0.5), endpoint=True, dtype =np.float32)\n",
    "    \n",
    "    y_train = x_train + 0.3*np.sin(2*np.pi*(x_train + eps_train)) + 0.3*np.sin(4*np.pi*(x_train + eps_train)) + eps_train\n",
    "    y_test =  x_test + 0.3*np.sin(2*np.pi*(x_test + eps_test)) + 0.3*np.sin(4*np.pi*(x_test + eps_test)) + eps_test\n",
    "    \n",
    "    x_train = np.atleast_2d(x_train).T\n",
    "    x_test = np.atleast_2d(x_test).T\n",
    "    \n",
    "    x_train_tensor = torch.Tensor(x_train)\n",
    "    y_train_tensor = torch.Tensor(y_train)\n",
    "    x_test_tensor =  torch.Tensor(x_test)\n",
    "    y_test_tensor =  torch.Tensor(y_test)\n",
    "    \n",
    "    plt.plot(x_train, y_train, 'rs', label='train')\n",
    "    plt.plot(x_test, y_test, 'k.', label='test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return x_train_tensor, y_train_tensor, x_test_tensor, y_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = toy_function(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes-by-Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/goncalves1/local/anaconda3/envs/mtl4c/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/goncalves1/local/anaconda3/envs/mtl4c/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n",
      "  0%|          | 1/5000 [00:00<08:40,  9.61it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-4c892308c5f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_elbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/anaconda3/envs/mtl4c/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/local/anaconda3/envs/mtl4c/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "from BBB_SMPP import MLP_BBB\n",
    "\n",
    "prior_pi = 0.5\n",
    "prior_sigma1 = 1 \n",
    "prior_sigma2 = 10\n",
    "net = MLP_BBB(1, 1, [5, 5], prior_pi, prior_sigma1, prior_sigma2, noise_tol=0.02)\n",
    "\n",
    "net.to(DEVICE)\n",
    "net.train()\n",
    "\n",
    "data = torch.tensor(x_train, dtype=torch.float32).to(DEVICE)\n",
    "target = torch.tensor(y_train, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)\n",
    "epochs = 5000\n",
    "\n",
    "loss_arr = list()\n",
    "for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "    optimizer.zero_grad()\n",
    "    # forward + backward + optimize\n",
    "    loss = net.sample_elbo(data, target, 1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_arr.append(loss.item())\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "plt.plot(loss_arr)\n",
    "# plt.yscale('log')\n",
    "plt.title('Loss during training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_post_samples = 100\n",
    "post_dist = np.zeros((len(x_test), n_post_samples + 1)) \n",
    "\n",
    "data_ts = torch.tensor(x_test, dtype=torch.float32)\n",
    "target_ts = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for j in range(n_post_samples): \n",
    "        post_dist[:, j] = net(data_ts).detach().numpy().ravel()\n",
    "    post_dist[:, n_post_samples] = net(data_ts).detach().numpy().ravel()\n",
    "\n",
    "y_mean = post_dist.mean(axis=1)\n",
    "sigma = post_dist.std(axis=1)\n",
    "\n",
    "plt.plot(x_train.numpy(), y_train.numpy(), 'k*', label='Train points')\n",
    "plt.plot(x_test.numpy(), y_test.numpy(), 'ro', label='Test points')\n",
    "plt.plot(x_test.numpy(), y_mean, 'b-', label='Test predictions')\n",
    "plt.fill(np.concatenate([x_test.numpy(), x_test.numpy()[::-1]]),\n",
    "         np.concatenate([y_mean - 1.9600 * sigma,\n",
    "                        (y_mean + 1.9600 * sigma)[::-1]]),\n",
    "         alpha=.5, fc='b', ec='None', label='95% confidence interval')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = torch.tensor([1,2,3,4,5])\n",
    "t1 = torch.tensor([1,2,3,4,5])\n",
    "\n",
    "# t0.unsqueeze_(-1)\n",
    "# t1.unsqueeze_(-1)\n",
    "# t2 = torch.cat((t0, t1), 1)\n",
    "# print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0.view(-1, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = torch.randn(3,)\n",
    "t1 = torch.randn(3,)\n",
    "t2 = torch.stack((t0, t1), dim=2).squeeze_()\n",
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_post_samples = 100\n",
    "post_dist = np.zeros((len(x_test), n_post_samples + 1)) \n",
    "\n",
    "data_ts = torch.tensor(x_test, dtype=torch.float32)\n",
    "target_ts = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "nnet.eval()\n",
    "with torch.no_grad():\n",
    "    for j in range(n_post_samples): \n",
    "        post_dist[:, j] = nnet(data_ts).detach().numpy().ravel()\n",
    "\n",
    "y_mean = post_dist.mean(axis=1)\n",
    "sigma = post_dist.std(axis=1)\n",
    "\n",
    "plt.plot(x_train, y_train, 'k*', label='Train points')\n",
    "plt.plot(x_test, y_test, 'ro', label='Test points')\n",
    "plt.plot(x_test, y_mean, 'b-', label='Test predictions')\n",
    "plt.fill(np.concatenate([x_test, x_test[::-1]]),\n",
    "         np.concatenate([y_mean - 1.9600 * sigma,\n",
    "                        (y_mean + 1.9600 * sigma)[::-1]]),\n",
    "         alpha=.5, fc='b', ec='None', label='95% confidence interval')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
