{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ExponentialLR\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "# from torchvision import datasets, transforms\n",
    "# from torchvision.utils import make_grid\n",
    "# from tqdm import tqdm, trange\n",
    "\n",
    "# writer = SummaryWriter()\n",
    "sns.set()\n",
    "sns.set_style(\"dark\")\n",
    "sns.set_palette(\"muted\")\n",
    "sns.set_color_codes(\"muted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? False\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "LOADER_KWARGS = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
    "print('GPU available? {}'.format(torch.cuda.is_available()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_function(N):\n",
    "    \n",
    "    noise_std = 0.02\n",
    "    eps_train = noise_std*np.random.randn(N,)\n",
    "    eps_test =  noise_std*np.random.randn(int(N*0.5),)\n",
    "    \n",
    "    \n",
    "    x_train = np.linspace(0, 0.5, N, endpoint=True, dtype =np.float32)\n",
    "    x_test =  np.linspace(-1, 1, int(N*0.5), endpoint=True, dtype =np.float32)\n",
    "    \n",
    "    y_train = x_train + 0.3*np.sin(2*np.pi*(x_train + eps_train)) + 0.3*np.sin(4*np.pi*(x_train + eps_train)) + eps_train\n",
    "    y_test =  x_test + 0.3*np.sin(2*np.pi*(x_test + eps_test)) + 0.3*np.sin(4*np.pi*(x_test + eps_test)) + eps_test\n",
    "    \n",
    "    x_train = np.atleast_2d(x_train).T\n",
    "    x_test = np.atleast_2d(x_test).T\n",
    "    \n",
    "    x_train_tensor = torch.Tensor(x_train)\n",
    "    y_train_tensor = torch.Tensor(y_train)\n",
    "    x_test_tensor =  torch.Tensor(x_test)\n",
    "    y_test_tensor =  torch.Tensor(y_test)\n",
    "    \n",
    "    plt.plot(x_train, y_train, 'rs', label='train')\n",
    "    plt.plot(x_test, y_test, 'k.', label='test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return x_train_tensor, y_train_tensor, x_test_tensor, y_test_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train, y_train, x_test, y_test = toy_function(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes-by-Backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-21c466c59735>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_elbo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "from BBB_SMPP import MLP_BBB\n",
    "\n",
    "prior_pi = 0.5\n",
    "prior_sigma1 = 1 \n",
    "prior_sigma2 = 10\n",
    "net = MLP_BBB(1, 1, [5, 5], prior_pi, prior_sigma1, prior_sigma2, noise_tol=0.02)\n",
    "\n",
    "net.to(DEVICE)\n",
    "net.train()\n",
    "\n",
    "data = torch.tensor(x_train, dtype=torch.float32).to(DEVICE)\n",
    "target = torch.tensor(y_train, dtype=torch.float32).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-2)\n",
    "epochs = 5000\n",
    "\n",
    "loss_arr = list()\n",
    "# for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    print(epoch)\n",
    "    optimizer.zero_grad()\n",
    "    # forward + backward + optimize\n",
    "    loss = net.sample_elbo(data, target, 1)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    loss_arr.append(loss.item())\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "plt.plot(loss_arr)\n",
    "# plt.yscale('log')\n",
    "plt.title('Loss during training')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_post_samples = 100\n",
    "post_dist = np.zeros((len(x_test), n_post_samples + 1)) \n",
    "\n",
    "data_ts = torch.tensor(x_test, dtype=torch.float32)\n",
    "target_ts = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for j in range(n_post_samples): \n",
    "        post_dist[:, j] = net(data_ts).detach().numpy().ravel()\n",
    "    post_dist[:, n_post_samples] = net(data_ts).detach().numpy().ravel()\n",
    "\n",
    "y_mean = post_dist.mean(axis=1)\n",
    "sigma = post_dist.std(axis=1)\n",
    "\n",
    "plt.plot(x_train.numpy(), y_train.numpy(), 'k*', label='Train points')\n",
    "plt.plot(x_test.numpy(), y_test.numpy(), 'ro', label='Test points')\n",
    "plt.plot(x_test.numpy(), y_mean, 'b-', label='Test predictions')\n",
    "plt.fill(np.concatenate([x_test.numpy(), x_test.numpy()[::-1]]),\n",
    "         np.concatenate([y_mean - 1.9600 * sigma,\n",
    "                        (y_mean + 1.9600 * sigma)[::-1]]),\n",
    "         alpha=.5, fc='b', ec='None', label='95% confidence interval')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_post_samples = 100\n",
    "post_dist = np.zeros((len(x_test), n_post_samples + 1)) \n",
    "\n",
    "data_ts = torch.tensor(x_test, dtype=torch.float32)\n",
    "target_ts = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "net.eval()\n",
    "with torch.no_grad():\n",
    "    for j in range(n_post_samples): \n",
    "        post_dist[:, j] = net(data_ts).detach().numpy().ravel()\n",
    "\n",
    "y_mean = post_dist.mean(axis=1)\n",
    "sigma = post_dist.std(axis=1)\n",
    "\n",
    "plt.plot(x_train.numpy(), y_train.numpy(), 'k*', label='Train points')\n",
    "plt.plot(x_test.numpy(), y_test.numpy(), 'ro', label='Test points')\n",
    "plt.plot(x_test.numpy(), y_mean, 'b-', label='Test predictions')\n",
    "plt.fill(np.concatenate([x_test.numpy(), x_test.numpy()[::-1]]),\n",
    "         np.concatenate([y_mean - 1.9600 * sigma,\n",
    "                        (y_mean + 1.9600 * sigma)[::-1]]),\n",
    "         alpha=.5, fc='b', ec='None', label='95% confidence interval')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
